<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>Wei Jin</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="Wei Jin">
<meta property="og:url" content="http://withwsf.github.io/index.html">
<meta property="og:site_name" content="Wei Jin">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Wei Jin">
<meta name="twitter:description">
  
    <link rel="alternative" href="/atom.xml" title="Wei Jin" type="application/atom+xml">
  
  
    <link rel="icon" href="http://www.picgifs.com/clip-art/cartoons/south-park/clip-art-south-park-362717.jpg">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="http://img01.deviantart.net/8e9f/i/2012/194/0/c/jake_the_dog_desktop_picture_by_partack-d571ypf.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Withwsf</a></h1>
		</hgroup>

		
		<p class="header-subtitle">We don&#39;t konw our destiny</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>標籤</li>
						
						
						<li>關於</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/wei_jin" title="zhihu">zhihu</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/Torch/" style="font-size: 20px;">Torch</a> <a href="/tags/数据挖掘/" style="font-size: 10px;">数据挖掘</a> <a href="/tags/机器学习/" style="font-size: 20px;">机器学习</a> <a href="/tags/阅读经典/" style="font-size: 10px;">阅读经典</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">基本上无害 (withwsf#gmail.com)</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Withwsf</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="http://img01.deviantart.net/8e9f/i/2012/194/0/c/jake_the_dog_desktop_picture_by_partack-d571ypf.jpg" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">Withwsf</h1>
			</hgroup>
			
			<p class="header-subtitle">We don&#39;t konw our destiny</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/wei_jin" title="zhihu">zhihu</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap">
  
    <article id="post-Python在Windows环境下处理文件路径问题最佳实践" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/12/30/Python在Windows环境下处理文件路径问题最佳实践/" class="article-date">
  	<time datetime="2015-12-30T06:45:38.000Z" itemprop="datePublished">2015-12-30</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/12/30/Python在Windows环境下处理文件路径问题最佳实践/">Python在Windows环境下处理文件路径问题最佳实践</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Windows中路径分隔符是反斜线’\’，而在Python中’\’又有转义符的作用，因而直接从windows资源管理器复制的路径在Python中是不能正常识别的。</p>
<ul>
<li><strong>最优实践：</strong><br>使用os.path.join来join不同的路径，比如<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">path=os.path.join(dirpath,filepath)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>也可以使用os.sep，python会根据不同的系统自动选择合适的路径分隔符<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">path=dirpath+os.sep+filepath</span><br></pre></td></tr></table></figure></p>
<ul>
<li><strong>次优方案</strong><br>可以将所有路径都使用正斜线’/‘，不管在Windows和Linux中都适用.</li>
<li><strong>不要使用</strong><br>在引用的字符串前面加上’r’可以将转义字符串(escaped strings )转换为原始字符串(raw strings)，可以解决部分问题。比如：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">file=open(<span class="string">'c:\myfile'</span>) <span class="comment">#打开错误</span></span><br><span class="line">file=open(<span class="string">r'c:\myfile'</span>)<span class="comment">#可以正确打开</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>但是’r’是为了方便书写正则表达式而不是为了解决Windows下文件路径问题而设计的特性，所以会遇到一下问题</p>
<blockquote>
<p>file=open(r’c:\dir\’+’myfile’)</p>
</blockquote>
<p>上述代码是错误的，虽然’\’失去了转义作用，但仍然有保护作用，其后的‘’’并不会被视为closing delimiter。</p>
<p>由此可见，使用r不仅没有完全解决问题，还会引入新的问题，所以最好不要使用。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-数据挖掘中的数据预处理" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/12/29/数据挖掘中的数据预处理/" class="article-date">
  	<time datetime="2015-12-29T14:13:02.000Z" itemprop="datePublished">2015-12-29</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/12/29/数据挖掘中的数据预处理/">数据挖掘中的数据预处理</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="0-0__u5173_u4E8E__u300ADATA_MINING_u2014Concepts_and_Techniques_u300B"><a href="#0-0__u5173_u4E8E__u300ADATA_MINING_u2014Concepts_and_Techniques_u300B" class="headerlink" title="0.0 关于 《DATA MINING—Concepts and Techniques》"></a>0.0 关于 《DATA MINING—Concepts and Techniques》</h3><p>《DATA MINING—Concepts and Techniques》是经典的数据挖掘入门书籍，内容囊括数据挖掘的基本概念、数据的预处理、数据的存储、数据中模式的挖掘、分类、聚类、异常检测等方面，作者是著名的韩家炜教授。数据的预处理在真实世界数据中是非常关键的一步，它既是不同数据挖掘应用的共同起点，又很大程度上影响了数据挖掘应用的效果。我将翻译、整理这本书中关于数据预处理的部分，如果有纰漏欢迎指正。</p>
<h3 id="0-1__u6570_u636E_u9884_u5904_u7406_u7EFC_u8FF0"><a href="#0-1__u6570_u636E_u9884_u5904_u7406_u7EFC_u8FF0" class="headerlink" title="0.1 数据预处理综述"></a>0.1 数据预处理综述</h3><ul>
<li>由于真实世界中的数据来源复杂、体积巨大，往往难以避免地存在缺失、噪声、不一致（inconsistencies）等问题。</li>
<li>当数据的维数过高时还会存在所谓的“<a href="http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf" target="_blank" rel="external">维数诅咒（Curse of dimensionality）</a>”问题，过高的维度不仅增加了计算量，反而可能会降低算法的效果。</li>
<li>有些算法对数据存在特殊的要求，比如KNN、Neural Networks、Clustering等基于距离（distance based）的算法在数据进行normalize之后效果会提升。</li>
</ul>
<p>解决上述问题需要在将数据送入算法之前进行预处理，具体包括<strong>Data Cleaning</strong>,<strong>Data Intergation</strong>，<strong>Data reduction</strong>,<strong>Data Transformation and Data Discretization</strong>等步骤。下面将对各个部分详细展开。</p>
<h3 id="1-__u6570_u636E_u6E05_u6D17_uFF08Data_Cleaning_uFF09"><a href="#1-__u6570_u636E_u6E05_u6D17_uFF08Data_Cleaning_uFF09" class="headerlink" title="1. 数据清洗（Data Cleaning）"></a>1. 数据清洗（Data Cleaning）</h3><p>数据清洗的主要作用是处理数据的某些纪录值缺失，平滑数据中的噪声、发现异常值，改正不一致。</p>
<h4 id="u503C_u7F3A_u5931"><a href="#u503C_u7F3A_u5931" class="headerlink" title="值缺失"></a>值缺失</h4><p>针对数据中某些记录的值缺失问题（比如用户销售数据中，有些顾客的收入信息缺失，有些顾客的年龄信息缺失），可以采用如下的方式：</p>
<ul>
<li>忽略存在缺失值的记录。在分类问题中，如果样本（本文中，’一个样本’和’一条记录’是同义词）的label缺失了，那么这个样本一定是要丢弃的。其他情况下，除非一条记录缺失了多个值，否则这种简单粗暴的方法往往效果不好，尤其当不同的属性值缺失状况相差很大时，效果会更差。</li>
<li>手动填写缺失的值。根据经验手工补上缺失的值，但是这种活儿谁愿意干呢？</li>
<li>用全局的常量来替代缺失值。再拿用户销售数据做例子，对于年龄缺失的纪录年龄全用unknow来代替，但是对于数据挖掘算法来说，young和unknow并没有什么本质的不同，都只是属性值的一种而已，所以所有年龄缺失的纪录在算法看来都是同一种年龄—-“unknow”,这反而可能会降低算法的效果。</li>
<li>使用中值和均值来替代缺失值。某种属性的中值和均值代表了此属性的平均趋势，用它们来代替缺失值不失为一种可行的方案。但是，当属性是“红、绿、蓝”这种离散值时显然不存在中值、均值的概念。</li>
<li>使用class-specific的中值和均值来代替缺失值。在有监督问题中，一个基本假设是label相同的样本属性也相似，那么，某个样本的缺失值，用其所在类别内的所有样本的在此属性的均值或中值来代替理应效果更好。</li>
<li>使用最可能的值来填充缺失值。用此样本的其他属性来推断缺失属性的最可能值，实际上这就变成了一个回归或分类问题（属性值连续时是回归问题，离散时是分类问题）。实际中常用<a href="https://en.wikipedia.org/wiki/Bayesian_inference" target="_blank" rel="external">贝叶斯推理</a>或决策树来解决上述问题。</li>
</ul>
<p>上述的第3-第6种方法都会引入偏差，因为补充的缺失值跟真实值很可能不同。第六种方法在现实中非常流行，因为它在推断缺失值时使用的信息最多，那么结果理应更准确。不过需要注意的是，有时缺失值也会提供有用的信息，比如在信用卡申请用户数据中，没有驾照号码很可能是因为没有汽车，而是否有汽车是评价信用等级很有用的信息。</p>
<h4 id="u566A_u58F0_uFF08noise_uFF09"><a href="#u566A_u58F0_uFF08noise_uFF09" class="headerlink" title="噪声（noise）"></a>噪声（noise）</h4><p>噪声是混在观测值的错误(error)或误差(variance)，具体去噪方式有以下几种：</p>
<ul>
<li>Binning。Data Bininig，又称为Bucketing，从字面意思来展开，就是把样本点按照一定的准则分配到不同的bin(bucket)中去，然后对每个样本点根据其所在bin内样本点的分布来赋一个新值，同一个bin的样本点被赋予的新值是一致的。对于一维数据，bin可以按照区间大小划分，也可以按照data frequency来划分，而每个bin的值可以选择分布在其中样本的均值、中值或者边界值。另外，CNN中的max-pooling层，也属于data binning的范畴，典型的max-pooling层bin的尺寸为2*2，选择每个bin中的最大值作为bin四个值的新值。</li>
<li>回归。如果变量之间存在依赖关系，即y=f(x)，那么我们可以设法求出依赖关系f，从而根据x来预测y，这也是回归问题的实质。实际中更常见的假设是P(y)=N(f(x))，N是正态分布。假设y是观测值且存在噪声，如果我们能求出x和y之间的依赖关系，从而根据x来更新y的值，就可以去除其中的随机噪声，这就是回归去噪的原理。</li>
<li>异常值检测。数据中的噪声可能有两种，一种是随机误差，另外一种可能是错误，比如我们手上有一份顾客的身高数据，其中某一位顾客的身高纪录是20m，很明显，这是一个错误，如果这个一场的样本进入了我们训练数据可能会对结果产生很大影响，这也是去噪中使用异常值检测的意义所在。当然，异常值检测远不止去噪这么一个应用，网络入侵检测、视频中行人异常行为检测、欺诈检测等都是异常值检测的应用。异常值检测方法也分为有监督，无监督和半监督方法，这里不再详细展开。<br>###2. 数据融合<br>所谓数据融合就是将不同来源的、异质的数据融合到一起。良好的数据融合可以减少数据中的冗余(redundacies)和不一致性(inconsistence)，进而提升后续步骤的精度和速度。数据融合包括如下几个步骤：<h4 id="u5B9E_u4F53_u8BC6_u522B_u95EE_u9898_uFF08Entity_Identification_Problem_uFF09"><a href="#u5B9E_u4F53_u8BC6_u522B_u95EE_u9898_uFF08Entity_Identification_Problem_uFF09" class="headerlink" title="实体识别问题（Entity  Identification Problem）"></a>实体识别问题（Entity  Identification Problem）</h4>实体识别中最主要的问题匹配不同的数据源中指向现实世界相同实体的纪录。比如分析有不同销售员纪录的14年和15年两年的销售数据，由于不同的销售员有不同的纪录习惯，顾客的名字纪录方式并不一样，一个销售员喜欢纪录全名（例如 Wardell Stephen Curry II），另外一个销售员喜欢将中间名省略（Wardell S Curry II ），虽然Wardell Stephen Curry II和Wardell S Curry II是现实世界中是同一名顾客，但计算机会识别为两位不同的顾客，解决这个问题就需要Entity Identification。一个常用的Entity Indentification Problem的解决算法是<a href="http://www.mit.edu/~andoni/LSH/" target="_blank" rel="external">LSH算法</a><br>另外一个问题是Schema integration, Schenma在这里指使用DBMS支持的形式化语言对一个数据库的结构化描述，Schema是构建一个数据库的蓝图。Schema intergration则是指，将若干个Schema合成一个global Schema，这个global Schema可以表达所有子Schema的要求（也就是一个总的蓝图）。属性的metadata（比如名称、取值范围、空值处理方法）可以帮助减少Schema Intergration的错误。<h4 id="u5197_u4F59_u548C_u76F8_u5173_u6027_u5206_u6790"><a href="#u5197_u4F59_u548C_u76F8_u5173_u6027_u5206_u6790" class="headerlink" title="冗余和相关性分析"></a>冗余和相关性分析</h4></li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/数据挖掘/">数据挖掘</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/阅读经典/">阅读经典</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-在torch中使用cuda进行训练" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/12/29/在torch中使用cuda进行训练/" class="article-date">
  	<time datetime="2015-12-29T07:50:33.000Z" itemprop="datePublished">2015-12-29</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/12/29/在torch中使用cuda进行训练/">在torch中使用cuda进行训练</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="0-__u8BF4_u660E"><a href="#0-__u8BF4_u660E" class="headerlink" title="0. 说明"></a>0. 说明</h3><p>本文介绍<strong>hdf5文件的读取</strong>、<strong>网络的定义</strong>与<strong>训练</strong>和<strong>测试</strong>，并强调了如何使用<strong>cuda</strong>对网络的训练、测试进行加速。</p>
<h3 id="1-__u8FC7_u7A0B_u4E0E_u4EE3_u7801"><a href="#1-__u8FC7_u7A0B_u4E0E_u4EE3_u7801" class="headerlink" title="1. 过程与代码"></a>1. 过程与代码</h3><ul>
<li><strong>1 安装hdf5</strong><br>按照<a href="https://github.com/deepmind/torch-hdf5/blob/master/doc/usage.md" target="_blank" rel="external">官方tutorial</a>安装torch对hdf5格式文件的支持。</li>
<li><p><strong>2 引入必要 package 并读入hdf5数据</strong></p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">require</span> <span class="string">'torch'</span>;<span class="comment">----如果是在itorch或itorch notbook中自动引入torch</span></span><br><span class="line"><span class="built_in">require</span> <span class="string">'hdf5'</span>;<span class="comment">----hdf5支持</span></span><br><span class="line"><span class="built_in">require</span> <span class="string">'nn'</span>; <span class="comment">----neural network modules 的实现</span></span><br><span class="line"><span class="built_in">require</span> <span class="string">'cutorch'</span>;<span class="comment">----cuda backend支持</span></span><br><span class="line"><span class="built_in">require</span> <span class="string">'cunn'</span>;<span class="comment">----neural network modules的cuda实现</span></span><br></pre></td></tr></table></figure>
<p>下面读入数据，假设train和test数据都是按照我<a href="http://withwsf.github.io/2015/12/23/torch-hdf5/">上篇文章</a>的格式所存储：</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">myFiletrian=hdf5.open(<span class="string">'mytrain.h5'</span>,<span class="string">'r'</span>)<span class="comment">----读取hdf5文件</span></span><br><span class="line">myFiletest=hdf5.open(<span class="string">'mytest.h5'</span>,<span class="string">'r'</span>)</span><br><span class="line"><span class="comment">----将读入的hdf5存到两个Table： trainset和testset中</span></span><br><span class="line">trainset=&#123;data=myFiletrian:read(<span class="string">'data'</span>):all(),label=myFiletrian:read(<span class="string">'label'</span>):all():byte()&#125;</span><br><span class="line">testset=&#123;data=myFiletest:read(<span class="string">'data'</span>):all(),label=myFiletest:read(<span class="string">'label'</span>):all():byte()&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>3 重载trainset的_index操作符并添加成员函数size()</strong><br>Lua中也存在面向对象的概念，Lua中的类可以通过Table+function模拟出来。这里将trainset视作一个类的对象，torch要求这个类有方法trainset:size()可以返回样本个数，使用操作符trainset[i]时返回第i个样本。</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">setmetatable</span>(trainset, <span class="comment">----重载index操作符</span></span><br><span class="line">    &#123;__index = <span class="function"><span class="keyword">function</span><span class="params">(t, i)</span></span> </span><br><span class="line">                    <span class="keyword">return</span> &#123;t.data[i], t.label[i]&#125; </span><br><span class="line">                <span class="keyword">end</span>&#125;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">trainset:size</span><span class="params">()</span></span><span class="comment">----添加成员函数 size()</span></span><br><span class="line">    <span class="keyword">return</span> self.data:size(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>4 建立一个网络</strong><br>我使用Torch的主要原因是因为Torch有3D conv模块，所以这里以模仿<strong>LeNet</strong>的3D conv网络为例：</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">net=nn.Sequential()</span><br><span class="line">net:add(nn.VolumetricConvolution(<span class="number">3</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>))<span class="comment">----添加3D conv层，输入3个feature cube，输出5个feature cube，filter size为3*3*3</span></span><br><span class="line">net:add(nn.VolumetricMaxPooling(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>))<span class="comment">----添加3D MaxPooling层</span></span><br><span class="line">net:add(nn.VolumetricConvolution(<span class="number">5</span>,<span class="number">16</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">4</span>))</span><br><span class="line">net:add(nn.VolumetricMaxPooling(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">net:add(nn.View(<span class="number">16</span>*<span class="number">4</span>*<span class="number">4</span>*<span class="number">4</span>))<span class="comment">----连接全连接层之前要使用nn.View()进行reshpe，nn.View()里面的参数需要根据</span></span><br><span class="line"><span class="comment">---（接上）数据的尺寸和前面的层来计算，比如在这里我是用的训练数据是3*24*24*24的cube,分别经过3*3*3和4*4*4 filter尺寸的两次卷积和两次maxpooling之后最终的输出是16个4*4*4*的feature cube ，那么nn.View()里面的参数就应该是16*4*4*4</span></span><br><span class="line">net:add(nn.Linear(<span class="number">16</span>*<span class="number">4</span>*<span class="number">4</span>*<span class="number">4</span>,<span class="number">120</span>))</span><br><span class="line">net:add(nn.Linear(<span class="number">120</span>,<span class="number">84</span>))<span class="comment">----nn.Linear(a,b)，设置a个输入neurons和b个输出neurons的全全连接层</span></span><br><span class="line">net:add(nn.Linear(<span class="number">84</span>,<span class="number">7</span>))</span><br><span class="line">net:add(nn.LogSoftMax())<span class="comment">-----输出每个类别概率P的log函数值log(P)</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>5 建立一个Solver</strong></p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">criterion=nn.ClassNLLCriterion()<span class="comment">----使用negatice log--likehood criterion ,即计算cross-entropy损失</span></span><br><span class="line"><span class="comment">----注意！Torch中训练数据的Label应该从1开始，比如有四类样本，那么label应该是1、2、3、4，不能从0开始，否则报错</span></span><br><span class="line">trainer=nn.StochasticGradient(net,criterion)<span class="comment">----使用随机梯度下降</span></span><br><span class="line">trainer.learningRate=<span class="number">0.001</span><span class="comment">----设置solver参数</span></span><br><span class="line">trainer.maxIteration=<span class="number">10</span><span class="comment">----迭代epoch数</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>6 将net、criterion、trainset和testset移动到GPU中</strong><br>如果要使用GPU加速，net、criterion、trainset和testset都需要移动到CPU内存中去</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">trainset.data=trainset.data:cuda()</span><br><span class="line">trainset.label=trainset.label:cuda()</span><br><span class="line">testset.label=trainset.label:cuda()</span><br><span class="line">testset.data=testset.data:cuda()</span><br><span class="line">criterion=criterion:cuda()</span><br><span class="line">net=net:cuda()</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>以trainset为例，移动到GPU之后是形式如下的对象</p>
<blockquote>
<p>{<br>  data : CudaTensor - size: 10500x3x24x24x24<br>  size : function: 0x42832ef0<br>  label : CudaTensor - size: 10500x1<br>}</p>
</blockquote>
<ul>
<li><strong>7 训练并测试网络</strong><br>有了上面的准备，网络的训练十分简单：<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer:train(trainset)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<blockquote>
<p>训练过程中输出如下：<br>Out[18]:StochasticGradient: training<br>Out[18]:current error = 1.9459465204875<br>Out[18]:current error = 1.941716547001<br>Out[18]:current error = 1.921697193475<br>Out[18]:current error = 1.8641934820811<br>Out[18]:current error = 1.5424795499416<br>Out[18]:current error = 1.3549344599815<br>Out[18]:current error = 1.2374953328995<br>Out[18]:current error = 1.152671923592<br>Out[18]:current error = 1.094293069022<br>Out[18]:current error = 1.0469601832571<br>StochasticGradient: you have reached the maximum number of iterations<br>training error = 1.0469601832571</p>
</blockquote>
<p>由于设置的最大epoch是10，所以在对trainset迭代了10次之后训练就结束了，接下来是网络的测试：<br><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">correct = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i=<span class="number">1</span>,<span class="number">3500</span> <span class="keyword">do</span> <span class="comment">----我的测试集有3500个cube</span></span><br><span class="line">    <span class="keyword">local</span> groundtruth = testset.label[i][<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">local</span> prediction = net:forward(testset.data[i])</span><br><span class="line">    <span class="keyword">local</span> confidences, indices = torch.sort(prediction, <span class="keyword">true</span>)</span><br><span class="line">    <span class="keyword">if</span> groundtruth == indices[<span class="number">1</span>] <span class="keyword">then</span></span><br><span class="line">       correct = correct + <span class="number">1</span> </span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="built_in">print</span>(correct, <span class="number">100</span>*correct/<span class="number">3500</span> .. <span class="string">' % '</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="2-__u603B_u7ED3"><a href="#2-__u603B_u7ED3" class="headerlink" title="2. 总结"></a>2. 总结</h3><p>使用Torch训练过程包括数据载入，网络定义，trainer定义，训练、测试几个部分，如果使用GPU加速，要将数据等对象移动到GPU中。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Torch/">Torch</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-torch-hdf5" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/12/23/torch-hdf5/" class="article-date">
  	<time datetime="2015-12-23T14:13:02.000Z" itemprop="datePublished">2015-12-23</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/12/23/torch-hdf5/">为Torch创建hdf5训练文件</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="1-_Torch_u4E0EHDF5"><a href="#1-_Torch_u4E0EHDF5" class="headerlink" title="1. Torch与HDF5"></a>1. Torch与HDF5</h3><p><strong><a href="http://torch.ch" target="_blank" rel="external">Torch</a></strong> 是用<strong>C/CUDA</strong>作为底层实现，用<strong>LuaJIT</strong>作为接口的机器学习算法框架。</p>
<p><strong><a href="http://docs.h5py.org/en/latest/quick.html" target="_blank" rel="external">HDF5</a></strong>是用于海量复杂数据集管理的技术,能够支持多种平台与多种语言接口（C，C++，Python等）。</p>
<p>Torch的tutorial只提供了处理images和random tensors的方法，并没有对其他格式提供示例。本文使用将对如何创建HDF5数据集以及如何在Torch中使用HDF5文件格式做一个梳理。</p>
<h3 id="2-__u4F7F_u7528Python_u521B_u5EFAHDF5_u6587_u4EF6"><a href="#2-__u4F7F_u7528Python_u521B_u5EFAHDF5_u6587_u4EF6" class="headerlink" title="2. 使用Python创建HDF5文件"></a>2. 使用Python创建HDF5文件</h3><ul>
<li><p><strong>1  在Python中安装 h5py</strong><br>在Ubuntu下 <code>sudo pip install h5py</code></p>
</li>
<li><p><strong>2  创建HDF5对象</strong><br>我们需要的HDF5文件在root (group) 下应该有“data”和“label”两个dataset，并在创建时指定这两个dataset的尺寸。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> h5py, os                             </span><br><span class="line">f=h5py.File(<span class="string">'train.h5'</span>,<span class="string">'w'</span>) <span class="comment">#以'w'模式创建一个名为'train.h5'的HDF5对象</span></span><br><span class="line">f.create_dataset(<span class="string">'data'</span>,(<span class="number">100</span>,<span class="number">3</span>,<span class="number">32</span>,<span class="number">32</span>),dtype=<span class="string">'f8'</span>) <span class="comment">#有100个样本，每个样本有三个channel，每个channle的尺寸是32*32</span></span><br><span class="line">f.create_dataset(<span class="string">'label'</span>,(<span class="number">100</span>,<span class="number">1</span>),dtype=<span class="string">'i'</span>) <span class="comment">#创建存放label的dataset，尺寸是100*1</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>3 写入数据</strong><br>写入数据其实很简单，只需要对dataset中的每个对象赋值即可。我们使用numpy随机生成的数据为例进行赋值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">  temp=np.random.random((<span class="number">3</span>,<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line">  f[<span class="string">'data'</span>][i]=temp <span class="comment">#写入data</span></span><br><span class="line">  f[<span class="string">'label'</span>][i]=i%<span class="number">4</span> <span class="comment">#写入label</span></span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>以上，即可生成一个用于训练的train.hdf5文件。</p>
<h3 id="3-__u5728torch_u4E2D_u4F7F_u7528HDF5_u6587_u4EF6"><a href="#3-__u5728torch_u4E2D_u4F7F_u7528HDF5_u6587_u4EF6" class="headerlink" title="3. 在torch中使用HDF5文件"></a>3. 在torch中使用HDF5文件</h3><p>在torch中读取HDF5文件需要用到<strong>torch-hdf5</strong>,可以参照<a href="https://github.com/deepmind/torch-hdf5/blob/master/doc/usage.md" target="_blank" rel="external">官方文档来安装</a>。<br><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">require</span> <span class="string">'hdf5'</span>;</span><br><span class="line">myFile=hdf5.open(<span class="string">'path_to_hdf5_file'</span>,<span class="string">'r'</span>) <span class="comment">-- 读入HDF5文件</span></span><br><span class="line">trainset=&#123;data=myFile:read(<span class="string">'data'</span>):all(),label=myFile:read(<span class="string">'label'</span>):all():byte()&#125;</span><br></pre></td></tr></table></figure></p>
<p>trainset是与<a href="https://github.com/soumith/cvpr2015/blob/master/Deep%20Learning%20with%20Torch.ipynb" target="_blank" rel="external">官方tutorial</a>读取’cifar10-train.t7’ 后同样的对象。<br><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">trainset <span class="comment">--输入trainset并执行后可以看到trainset的信息如下</span></span><br><span class="line"> <span class="comment">----------------执行输出的信息-------------------------------------------------</span></span><br><span class="line">｛</span><br><span class="line">data : DoubleTensor - size: <span class="number">100</span>×<span class="number">3</span>×<span class="number">32</span>×<span class="number">32</span></span><br><span class="line">label : ByteTensor -size: <span class="number">100</span>×<span class="number">1</span></span><br><span class="line">｝</span><br></pre></td></tr></table></figure></p>
<p><strong>按照上述的方法创建trainset和testset并读取数据之后，就接着可以进行训练了，由于内容不在本文范围内，所以略过。</strong></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Torch/">Torch</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
  
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2016 Withwsf
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: true
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</body>
</html>